{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone & LLM Integration Tests\n",
    "\n",
    "This notebook tests the integration between Pinecone vector search and the LLM response system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful\n",
      "Pinecone API Key present: True\n",
      "OpenAI API Key present: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import our modules\n",
    "from project_search import search_projects, get_project_by_id\n",
    "from llm import LlmClient\n",
    "from custom_types import (\n",
    "    ResponseRequiredRequest,\n",
    "    ResponseResponse,\n",
    "    Utterance,\n",
    "    ToolCallInvocationResponse,\n",
    "    MetadataResponse\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"Pinecone API Key present: {bool(os.getenv('PINECONE_API_KEY'))}\")\n",
    "print(f\"OpenAI API Key present: {bool(os.getenv('OPENAI_API_KEY'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Direct Pinecone Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for AI projects...\n",
      "\n",
      "1. AI Interview Coach (Score: 0.292)\n",
      "   ID: ai-interview-coach\n",
      "   Details: Overview\n",
      "AI Interview Coach helps candidates rehearse interviews in realistic conditions. It provides timed rounds, interviewer personas, and supports...\n",
      "\n",
      "2. Flavor Finder (Score: 0.22)\n",
      "   ID: flavor-finder\n",
      "   Details: Overview\n",
      "A practical cooking companion that adapts recipes to your pantry and goals. Focus on saving time and reducing waste.\n",
      "\n",
      "Features\n",
      "- Ingredient s...\n",
      "\n",
      "3. Lingua Mentor (Score: 0.209)\n",
      "   ID: lingua-mentor\n",
      "   Details: Overview\n",
      "A tutor that focuses on conversation, feedback, and memory. Role-play covers travel, work, and daily life.\n",
      "\n",
      "Features\n",
      "- Real-time pronunciatio...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test searching for AI projects\n",
    "print(\"üîç Searching for AI projects...\\n\")\n",
    "ai_projects = search_projects(\"artificial intelligence machine learning\", top_k=3)\n",
    "\n",
    "for i, project in enumerate(ai_projects, 1):\n",
    "    print(f\"{i}. {project['name']} (Score: {project['score']})\")\n",
    "    print(f\"   ID: {project['id']}\")\n",
    "    print(f\"   Details: {project['details'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Searching for hackathon winners...\n",
      "\n",
      "1. Chain Sage\n",
      "   ID: chain-sage\n",
      "   GitHub: https://github.com/example/chain-sage\n",
      "   Demo: /vercel.svg\n",
      "\n",
      "2. Pulse Guardian\n",
      "   ID: pulse-guardian\n",
      "   Demo: https://www.youtube.com/watch?v=H8UdKZf8uWk\n",
      "\n",
      "3. Quillboard\n",
      "   ID: quillboard\n",
      "   GitHub: https://github.com/example/quillboard\n",
      "   Demo: https://www.youtube.com/watch?v=Z9AYPxH5NTM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test searching for hackathon projects\n",
    "print(\"üèÜ Searching for hackathon winners...\\n\")\n",
    "hackathon_projects = search_projects(\"hackathon winner prize\", top_k=3)\n",
    "\n",
    "for i, project in enumerate(hackathon_projects, 1):\n",
    "    print(f\"{i}. {project['name']}\")\n",
    "    print(f\"   ID: {project['id']}\")\n",
    "    if 'github' in project:\n",
    "        print(f\"   GitHub: {project['github']}\")\n",
    "    if 'demo' in project:\n",
    "        print(f\"   Demo: {project['demo']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Fetching project: interviewgpt\n",
      "\n",
      "Project not found\n"
     ]
    }
   ],
   "source": [
    "# Test fetching a specific project\n",
    "project_id = \"interviewgpt\"\n",
    "print(f\"üì¶ Fetching project: {project_id}\\n\")\n",
    "\n",
    "project = get_project_by_id(project_id)\n",
    "if project:\n",
    "    print(f\"Name: {project['name']}\")\n",
    "    print(f\"\\nSummary:\\n{project['summary']}\")\n",
    "    print(f\"\\nDetails:\\n{project['details']}\")\n",
    "else:\n",
    "    print(\"Project not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test LLM with Project Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM Client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM client\n",
    "client = LlmClient(\"test-notebook\", debug=False)\n",
    "print(\"‚úÖ LLM Client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_llm_search(user_message):\n",
    "    \"\"\"Test LLM response with project search.\"\"\"\n",
    "    print(f\"üë§ User: {user_message}\\n\")\n",
    "    print(\"ü§ñ Bill: \", end=\"\")\n",
    "    \n",
    "    request = ResponseRequiredRequest(\n",
    "        interaction_type=\"response_required\",\n",
    "        response_id=1,\n",
    "        transcript=[Utterance(role=\"user\", content=user_message)]\n",
    "    )\n",
    "    \n",
    "    tool_called = None\n",
    "    project_id = None\n",
    "    full_response = \"\"\n",
    "    \n",
    "    async for response in client.draft_response(request):\n",
    "        if isinstance(response, ResponseResponse) and response.content:\n",
    "            print(response.content, end=\"\", flush=True)\n",
    "            full_response += response.content\n",
    "            \n",
    "        elif isinstance(response, ToolCallInvocationResponse):\n",
    "            tool_called = response.name\n",
    "            if response.name == \"search_projects\":\n",
    "                print(f\"\\n\\nüìä [Searching projects with query...]\")\n",
    "            elif response.name == \"display_project\":\n",
    "                import json\n",
    "                try:\n",
    "                    args = json.loads(response.arguments)\n",
    "                    project_id = args.get(\"id\")\n",
    "                    print(f\"\\n\\nüñ•Ô∏è [Displaying project: {project_id}]\")\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(f\"\\nüìå Summary:\")\n",
    "    print(f\"   Tool called: {tool_called or 'None'}\")\n",
    "    if project_id:\n",
    "        print(f\"   Project displayed: {project_id}\")\n",
    "    print(f\"   Response length: {len(full_response)} characters\")\n",
    "    \n",
    "    return full_response, tool_called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: What AI projects have you built?\n",
      "\n",
      "ü§ñ Bill: \n",
      "\n",
      "üìä [Searching projects with query...]\n",
      "I've built a few really cool AI projects. There's the AI Interview Coach, which helps candidates practice interviews with realistic conditions. It offers timed rounds, different interviewer personas, and gives detailed feedback after each session. \n",
      "\n",
      "Then there's Flavor Finder, a cooking companion that adjusts recipes based on what you've got in your pantry. It even scans ingredients and suggests substitutions.\n",
      "\n",
      "Lastly, there's the AR Home Designer, which lets you visualize home interiors with augmented reality. You can place and resize 3D models accurately and compare styles with A/B snapshots.\n",
      "\n",
      "Which one sounds the most interesting to you?\n",
      "\n",
      "\n",
      "üìå Summary:\n",
      "   Tool called: search_projects\n",
      "   Response length: 648 characters\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Ask about AI projects\n",
    "response, tool = await test_llm_search(\"What AI projects have you built?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: Tell me about InterviewGPT and show it to me\n",
      "\n",
      "ü§ñ Bill: \n",
      "\n",
      "üñ•Ô∏è [Displaying project: interviewgpt]\n",
      "I can only share information about my background, education, projects, and professional experience. Feel free to ask me about my hackathon wins, work at RingCentral, or any of my technical projects!\n",
      "\n",
      "\n",
      "üìå Summary:\n",
      "   Tool called: display_project\n",
      "   Project displayed: interviewgpt\n",
      "   Response length: 198 characters\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Ask about a specific project\n",
    "response, tool = await test_llm_search(\"Tell me about InterviewGPT and show it to me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ User: What's your most impressive hackathon win?\n",
      "\n",
      "ü§ñ Bill: I've got to say, my most impressive hackathon win was at the UC Berkeley AI Hackathon. We built an AI-powered interview coach that uses GPT-4 to simulate realistic interview scenarios. It was super intense but so rewarding to see it get recognized. Winning that was a game-changer for me! What about you? Ever participated in a hackathon?\n",
      "\n",
      "\n",
      "üìå Summary:\n",
      "   Tool called: None\n",
      "   Response length: 338 characters\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Ask about hackathon wins\n",
    "response, tool = await test_llm_search(\"What's your most impressive hackathon win?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Multi-Turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Conversation History:\n",
      "   User: Hi Bill!\n",
      "   Bill: Hey! I'm Bill Zhang, engineer and hackathon enthusiast. How can I help you today?\n",
      "\n",
      "üë§ User: I'm interested in AI. What have you built in that space?\n",
      "\n",
      "ü§ñ Bill: I've built a few cool AI projects. There's InterviewGPT, my AI interview coach that simulates realistic interviews and gives feedback. I also created GetItDone, an AI task management tool that helps you prioritize tasks. Plus, there's SmartChef, which suggests recipes based on what you have at home. Which one sounds more interesting to you?\n",
      "\n",
      "üìä Tools called: []\n"
     ]
    }
   ],
   "source": [
    "async def test_conversation():\n",
    "    \"\"\"Test a multi-turn conversation.\"\"\"\n",
    "    conversation = [\n",
    "        Utterance(role=\"user\", content=\"Hi Bill!\"),\n",
    "        Utterance(role=\"agent\", content=\"Hey! I'm Bill Zhang, engineer and hackathon enthusiast. How can I help you today?\"),\n",
    "        Utterance(role=\"user\", content=\"I'm interested in AI. What have you built in that space?\")\n",
    "    ]\n",
    "    \n",
    "    print(\"üí¨ Conversation History:\")\n",
    "    for utt in conversation[:-1]:\n",
    "        role = \"User\" if utt.role == \"user\" else \"Bill\"\n",
    "        print(f\"   {role}: {utt.content}\")\n",
    "    \n",
    "    print(f\"\\nüë§ User: {conversation[-1].content}\")\n",
    "    print(\"\\nü§ñ Bill: \", end=\"\")\n",
    "    \n",
    "    request = ResponseRequiredRequest(\n",
    "        interaction_type=\"response_required\",\n",
    "        response_id=10,\n",
    "        transcript=conversation\n",
    "    )\n",
    "    \n",
    "    tools_called = []\n",
    "    \n",
    "    async for response in client.draft_response(request):\n",
    "        if isinstance(response, ResponseResponse) and response.content:\n",
    "            print(response.content, end=\"\", flush=True)\n",
    "            \n",
    "        elif isinstance(response, ToolCallInvocationResponse):\n",
    "            tools_called.append(response.name)\n",
    "            print(f\"\\n[Tool: {response.name}]\", end=\"\")\n",
    "    \n",
    "    print(f\"\\n\\nüìä Tools called: {tools_called}\")\n",
    "\n",
    "await test_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Markdown Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Checking response for markdown...\n",
      "\n",
      "‚úÖ No markdown found! Response is clean.\n",
      "\n",
      "Full response preview (first 200 chars):\n",
      "Let me tell you about my favorite project: InterviewGPT. It's an AI-powered interview coaching tool that I designed for a hackathon at UC Berkeley, and it actually won first place there, which was a c...\n"
     ]
    }
   ],
   "source": [
    "async def check_for_markdown(user_message):\n",
    "    \"\"\"Check if response contains markdown.\"\"\"\n",
    "    request = ResponseRequiredRequest(\n",
    "        interaction_type=\"response_required\",\n",
    "        response_id=20,\n",
    "        transcript=[Utterance(role=\"user\", content=user_message)]\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    async for response in client.draft_response(request):\n",
    "        if isinstance(response, ResponseResponse) and response.content:\n",
    "            full_response += response.content\n",
    "    \n",
    "    # Check for common markdown patterns\n",
    "    markdown_patterns = [\n",
    "        ('**', 'Bold asterisks'),\n",
    "        ('*', 'Italics asterisks'),\n",
    "        ('##', 'Headers'),\n",
    "        ('`', 'Backticks'),\n",
    "        ('[', 'Link brackets'),\n",
    "        ('](', 'Link syntax')\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìù Checking response for markdown...\\n\")\n",
    "    found_markdown = False\n",
    "    \n",
    "    for pattern, description in markdown_patterns:\n",
    "        if pattern in full_response:\n",
    "            print(f\"‚ùå Found {description}: '{pattern}'\")\n",
    "            found_markdown = True\n",
    "            # Show context\n",
    "            index = full_response.find(pattern)\n",
    "            start = max(0, index - 20)\n",
    "            end = min(len(full_response), index + 20)\n",
    "            print(f\"   Context: ...{full_response[start:end]}...\\n\")\n",
    "    \n",
    "    if not found_markdown:\n",
    "        print(\"‚úÖ No markdown found! Response is clean.\")\n",
    "    \n",
    "    print(f\"\\nFull response preview (first 200 chars):\\n{full_response[:200]}...\")\n",
    "    \n",
    "    return found_markdown\n",
    "\n",
    "# Test for markdown\n",
    "has_markdown = await check_for_markdown(\"Tell me about your best project with all the technical details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è Testing search performance...\n",
      "\n",
      "Query: 'machine learning'\n",
      "   Found: 3 projects\n",
      "   Time: 0.805 seconds\n",
      "   Top result: AI Interview Coach (Score: 0.215)\n",
      "\n",
      "Query: 'web development'\n",
      "   Found: 3 projects\n",
      "   Time: 0.744 seconds\n",
      "   Top result: AR Home Designer (Score: 0.278)\n",
      "\n",
      "Query: 'hackathon'\n",
      "   Found: 3 projects\n",
      "   Time: 0.753 seconds\n",
      "   Top result: Quillboard (Score: 0.265)\n",
      "\n",
      "Query: 'real-time'\n",
      "   Found: 3 projects\n",
      "   Time: 0.834 seconds\n",
      "   Top result: Quillboard (Score: 0.245)\n",
      "\n",
      "Query: 'mobile app'\n",
      "   Found: 3 projects\n",
      "   Time: 0.813 seconds\n",
      "   Top result: Campus Wayfinder (Score: 0.317)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Test search performance\n",
    "queries = [\n",
    "    \"machine learning\",\n",
    "    \"web development\",\n",
    "    \"hackathon\",\n",
    "    \"real-time\",\n",
    "    \"mobile app\"\n",
    "]\n",
    "\n",
    "print(\"‚è±Ô∏è Testing search performance...\\n\")\n",
    "\n",
    "for query in queries:\n",
    "    start = time.time()\n",
    "    results = search_projects(query, top_k=3)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"   Found: {len(results)} projects\")\n",
    "    print(f\"   Time: {elapsed:.3f} seconds\")\n",
    "    if results:\n",
    "        print(f\"   Top result: {results[0]['name']} (Score: {results[0]['score']:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Project Search Statistics\n",
      "\n",
      "Total unique projects found: 10\n",
      "\n",
      "Most frequently appearing projects:\n",
      "   AI Interview Coach: appeared in 7 searches\n",
      "   Flavor Finder: appeared in 4 searches\n",
      "   Smart Garden Monitor: appeared in 4 searches\n",
      "   Lingua Mentor: appeared in 4 searches\n",
      "   AR Home Designer: appeared in 3 searches\n"
     ]
    }
   ],
   "source": [
    "# Get statistics about the projects\n",
    "from collections import defaultdict\n",
    "\n",
    "# Search for all types of projects\n",
    "all_queries = [\n",
    "    \"artificial intelligence\",\n",
    "    \"web development\",\n",
    "    \"mobile application\",\n",
    "    \"data analysis\",\n",
    "    \"hackathon\",\n",
    "    \"real-time\",\n",
    "    \"machine learning\"\n",
    "]\n",
    "\n",
    "project_counts = defaultdict(int)\n",
    "unique_projects = set()\n",
    "\n",
    "for query in all_queries:\n",
    "    results = search_projects(query, top_k=5)\n",
    "    for project in results:\n",
    "        unique_projects.add(project['id'])\n",
    "        project_counts[project['id']] += 1\n",
    "\n",
    "print(\"üìä Project Search Statistics\\n\")\n",
    "print(f\"Total unique projects found: {len(unique_projects)}\")\n",
    "print(f\"\\nMost frequently appearing projects:\")\n",
    "\n",
    "sorted_projects = sorted(project_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for project_id, count in sorted_projects[:5]:\n",
    "    project = get_project_by_id(project_id)\n",
    "    if project:\n",
    "        print(f\"   {project['name']}: appeared in {count} searches\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfoliov3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
